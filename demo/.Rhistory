x <- rnorm(1000, 10, 5)
hist(x)
y <- sample(x, size = length(x))
y <- sample(x, size = length(x), replace = T)
hist(y)
hist(x)
qqplot(x,y)
qqline(x,y)
hist(y)
hist(x)
qqplot(x,y)
avg.vals <- vector(length = length(x))
x <- rnorm(1000, 10, 5)
hist(x)
avg.vals <- vector(length = 1000)
source("~/.active-rstudio-document", echo=TRUE)
hist(y)
his(avg.vals)
hist(avg.vals)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
qqplot(avg.vals, avg.vals2)
abline(a = 1, b = 0)
abline(a = 0, b = 1)
?na.approx
# Description:
# Performs emission event detection, localization, and quantification
# using output from the Gaussian puff dispersion model and CMS concentration
# observations.
# Author: William Daniels (wdaniels@mines.edu)
# Last Updated: December 2023
# Clear environment
if(!is.null(dev.list())){dev.off()}
rm(list = ls())
# Import necessary libraries
library(lubridate)
library(zoo)
library(rstudioapi)
if (commandArgs()[1] == "RStudio"){
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
}
# START USER INPUT
#---------------------------------------------------------------------------
# Set path to simulation configuration file
config.file.dir <- '../input_data/DLQ_config.txt'
# END OF USER INPUT - NO MODIFICATION NECESSARY BELOW THIS POINT
#---------------------------------------------------------------------------
# STEP 1: READ IN CONFIG FILE AND SET UP PARAMETERS AND DIRECTORY STRUCTURE
#---------------------------------------------------------------------------
# Read in config file
config <- suppressWarnings(read.table(config.file.dir))
config <- strsplit(config[,1], "=")
# Parse out config file
parameters <- sapply(config, function(X) X[1])
values <- sapply(config, function(X) X[2])
# Get parameter values
gap.time           <- as.numeric(values[parameters == "gap.time"])
length.threshold   <- as.numeric(values[parameters == "length.threshold"])
do.event.detection <- as.logical(values[parameters == "do.event.detection"])
# Get directories
simulation.data.path <-            as.character(values[parameters == "simulation.data.path"])
output.file.path <-                as.character(values[parameters == "output.file.path"])
helper.spike.detection.alg.path <- as.character(values[parameters == "helper.spike.detection.alg.path"])
# Source helper files which contain helper functions
source(helper.spike.detection.alg.path)
# Read in simulation data
data <- readRDS(simulation.data.path)
# Pull out sensor observations and replace NA's that are not on edge of
# the time series with interpolated values
obs <- na.approx(data$obs, na.rm = F)
# Number of sensors
n.r <- ncol(obs)
# Pull out time stamps of observations and simulations
times <- data$times
# Pull out the simulation predictions
sims <- data[5:length(data)]
# Grab source info
n.s <- length(sims)
source.names <- names(sims)
# Define function to create a logarithmic spaced sequence (used later)
lseq <- function(from, to, length.out) {
exp(seq(log(from), log(to), length.out = length.out))
}
# Get range of times, rounded to 30-minute intervals
date.range <- range(data$times)
date.range[1] <- ceiling_date(date.range[1], unit = "30 minutes")
date.range[2] <- floor_date(date.range[2], unit = "30 minutes")
# Times separating the 30-minute intervals
int.breaks <- seq(date.range[1], date.range[2], by = "30 min")
int.breaks
t = 2
this.mask <- spikes$time %within% interval(int.breaks[t], int.breaks[t+1])
interval(int.breaks[t], int.breaks[t+1])
# Skip sensors that have only NA values
to.use <- which(apply(obs, 2, function(X) !all(is.na(X))))
# Loop through sensor units
for (j in to.use){
# Grab observations from this sensor
this.raw.obs <- obs[,j]
# Remove the NA's at the beginning and end of the time series
# (some sensors start late or end early)
to.keep <- !is.na(this.raw.obs)
trimmed.obs <- this.raw.obs[to.keep]
trimmed.times <- times[to.keep]
# Flag spikes
spikes <- find.spikes(obs = trimmed.obs,
times = trimmed.times,
amp.threshold = 0.75,
make.plot = F)
# Add points immediately before and after the spike to the spike mask
# This better captures the full event, as there is some delay between the
# start of an emission and when the sensors first see an enhancement
for (i in na.omit(unique(spikes$events))){
min.ind <- min(which(spikes$events == i))
max.ind <- max(which(spikes$events == i))
spikes$events[c(max(c(min.ind-1, 1)), min(c(max.ind+1,nrow(spikes))))] <- i
}
# Pull out integers that uniquely identify an event
event.nums <- na.omit(unique(spikes$events))
# If there are at least two events
if (length(event.nums) > 1){
# Loop through spikes and combine spikes that are separated by less than gap.time minutes
for (i in 2:length(event.nums)){
# Mask in this spike and last spike
this.spike <- spikes$events == event.nums[i]
previous.spike <- spikes$events == event.nums[i-1]
# Clean up
this.spike[is.na(this.spike)] <- F
previous.spike[is.na(previous.spike)] <- F
# Get start time of current spike and end time of previous spike
this.spike.start.time <- spikes$time[this.spike][1]
previous.spike.end.time <- spikes$time[previous.spike][length(spikes$time[previous.spike])]
# Compute time difference
time.diff <- difftime(this.spike.start.time, previous.spike.end.time, units = "mins")
# Check gap
if (minutes(time.diff) < minutes(gap.time)){
spikes$events[this.spike] <- event.nums[i-1]
event.nums[i] <- event.nums[i-1]
}
}
}
# Grab the new event numbers after combining events in the previous for loop
event.nums <- na.omit(unique(spikes$events))
# If there are any events
if (length(event.nums) > 0){
# Loop through events and (1) fill in any gaps between events with the correct
# event number, and (2) estimate background as mean of first and last spike
# points, which occur before the sharp increase and after the spike has
# returned to return.threshold percent of the max value
for (i in 1:length(event.nums)){
# Fill in gaps
first.ob <- min(which(spikes$events == event.nums[i]))
last.ob <- max(which(spikes$events == event.nums[i]))
this.mask <- first.ob:last.ob
spikes$events[this.mask] <- event.nums[i]
# Estimate background using observations before and after spike
# This is just the first and last observation within the spike mask,
# since we already added the points before and after the spike to the
# spike mask earlier on
b.left <- trimmed.obs[first.ob]
b.right <- trimmed.obs[last.ob]
b <- mean(c(b.left, b.right))
# Remove background from this spike
trimmed.obs[this.mask] <- trimmed.obs[this.mask] - b
}
}
# Remove background from all non-spike data. Since by definition these points
# are not in an event, their concentration value is directly taken as the
# background estimate. Hence removing background is just setting the value to zero
trimmed.obs[is.na(spikes$events)] <- 0
# Set any negative values to zero. Negative value would arise if the
# background estimate was too large (greater than actual concentration value)
trimmed.obs[trimmed.obs < 0] <- 0
# Save background removed data
obs[to.keep, j] <- trimmed.obs
}
this.mask <- spikes$time %within% interval(int.breaks[t], int.breaks[t+1])
spikes$time[this.mask]
# Description:
# Performs emission event detection, localization, and quantification
# using output from the Gaussian puff dispersion model and CMS concentration
# observations.
# Author: William Daniels (wdaniels@mines.edu)
# Last Updated: December 2023
# Clear environment
if(!is.null(dev.list())){dev.off()}
rm(list = ls())
# Import necessary libraries
library(lubridate)
library(zoo)
library(rstudioapi)
if (commandArgs()[1] == "RStudio"){
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
}
# START USER INPUT
#---------------------------------------------------------------------------
# Set path to simulation configuration file
config.file.dir <- '../input_data/DLQ_config.txt'
# END OF USER INPUT - NO MODIFICATION NECESSARY BELOW THIS POINT
#---------------------------------------------------------------------------
# STEP 1: READ IN CONFIG FILE AND SET UP PARAMETERS AND DIRECTORY STRUCTURE
#---------------------------------------------------------------------------
# Read in config file
config <- suppressWarnings(read.table(config.file.dir))
config <- strsplit(config[,1], "=")
# Parse out config file
parameters <- sapply(config, function(X) X[1])
values <- sapply(config, function(X) X[2])
# Get parameter values
gap.time           <- as.numeric(values[parameters == "gap.time"])
length.threshold   <- as.numeric(values[parameters == "length.threshold"])
do.event.detection <- as.logical(values[parameters == "do.event.detection"])
# Get directories
simulation.data.path <-            as.character(values[parameters == "simulation.data.path"])
output.file.path <-                as.character(values[parameters == "output.file.path"])
helper.spike.detection.alg.path <- as.character(values[parameters == "helper.spike.detection.alg.path"])
# Source helper files which contain helper functions
source(helper.spike.detection.alg.path)
# Read in simulation data
data <- readRDS(simulation.data.path)
# Pull out sensor observations and replace NA's that are not on edge of
# the time series with interpolated values
obs <- na.approx(data$obs, na.rm = F)
# Number of sensors
n.r <- ncol(obs)
# Pull out time stamps of observations and simulations
times <- data$times
# Pull out the simulation predictions
sims <- data[5:length(data)]
# Grab source info
n.s <- length(sims)
source.names <- names(sims)
# Define function to create a logarithmic spaced sequence (used later)
lseq <- function(from, to, length.out) {
exp(seq(log(from), log(to), length.out = length.out))
}
# STEP 2: REMOVE BACKGROUND FROM OBSERVATIONS
#---------------------------------------------------------------------------
# Skip sensors that have only NA values
to.use <- which(apply(obs, 2, function(X) !all(is.na(X))))
# Loop through sensor units
for (j in to.use){
# Grab observations from this sensor
this.raw.obs <- obs[,j]
# Remove the NA's at the beginning and end of the time series
# (some sensors start late or end early)
to.keep <- !is.na(this.raw.obs)
trimmed.obs <- this.raw.obs[to.keep]
trimmed.times <- times[to.keep]
# Flag spikes
spikes <- find.spikes(obs = trimmed.obs,
times = trimmed.times,
amp.threshold = 0.75,
make.plot = F)
# Add points immediately before and after the spike to the spike mask
# This better captures the full event, as there is some delay between the
# start of an emission and when the sensors first see an enhancement
for (i in na.omit(unique(spikes$events))){
min.ind <- min(which(spikes$events == i))
max.ind <- max(which(spikes$events == i))
spikes$events[c(max(c(min.ind-1, 1)), min(c(max.ind+1,nrow(spikes))))] <- i
}
# Pull out integers that uniquely identify an event
event.nums <- na.omit(unique(spikes$events))
# If there are at least two events
if (length(event.nums) > 1){
# Loop through spikes and combine spikes that are separated by less than gap.time minutes
for (i in 2:length(event.nums)){
# Mask in this spike and last spike
this.spike <- spikes$events == event.nums[i]
previous.spike <- spikes$events == event.nums[i-1]
# Clean up
this.spike[is.na(this.spike)] <- F
previous.spike[is.na(previous.spike)] <- F
# Get start time of current spike and end time of previous spike
this.spike.start.time <- spikes$time[this.spike][1]
previous.spike.end.time <- spikes$time[previous.spike][length(spikes$time[previous.spike])]
# Compute time difference
time.diff <- difftime(this.spike.start.time, previous.spike.end.time, units = "mins")
# Check gap
if (minutes(time.diff) < minutes(gap.time)){
spikes$events[this.spike] <- event.nums[i-1]
event.nums[i] <- event.nums[i-1]
}
}
}
# Grab the new event numbers after combining events in the previous for loop
event.nums <- na.omit(unique(spikes$events))
# If there are any events
if (length(event.nums) > 0){
# Loop through events and (1) fill in any gaps between events with the correct
# event number, and (2) estimate background as mean of first and last spike
# points, which occur before the sharp increase and after the spike has
# returned to return.threshold percent of the max value
for (i in 1:length(event.nums)){
# Fill in gaps
first.ob <- min(which(spikes$events == event.nums[i]))
last.ob <- max(which(spikes$events == event.nums[i]))
this.mask <- first.ob:last.ob
spikes$events[this.mask] <- event.nums[i]
# Estimate background using observations before and after spike
# This is just the first and last observation within the spike mask,
# since we already added the points before and after the spike to the
# spike mask earlier on
b.left <- trimmed.obs[first.ob]
b.right <- trimmed.obs[last.ob]
b <- mean(c(b.left, b.right))
# Remove background from this spike
trimmed.obs[this.mask] <- trimmed.obs[this.mask] - b
}
}
# Remove background from all non-spike data. Since by definition these points
# are not in an event, their concentration value is directly taken as the
# background estimate. Hence removing background is just setting the value to zero
trimmed.obs[is.na(spikes$events)] <- 0
# Set any negative values to zero. Negative value would arise if the
# background estimate was too large (greater than actual concentration value)
trimmed.obs[trimmed.obs < 0] <- 0
# Save background removed data
obs[to.keep, j] <- trimmed.obs
}
# STEP 3: EVENT DETECTION
#---------------------------------------------------------------------------
# Compute maximum concentration value across sensors for each minute
# Note that since all non-spike observations have been set to zero, any
# non-zero value in the max.obs time series should be considered an event
# (and hence no need to run the spike detection algorithm again)
max.obs <- apply(obs, 1, max, na.rm = T)
# Estimate emission start and end times
if (do.event.detection){
# Create data frame with time steps and event mask
spikes <- data.frame(time = times, events = max.obs > 0)
# Find gaps between events that are shorter than gap.time and turn them into events
#   to.replace holds the indices that need to be switched from F to T
#   first.gap is an indicator for the first gap (which should not be replaced,
#   regardless of length)
#   false.seq holds the indices of each sequence of FALSEs (non-events)
to.replace <- c()
first.gap <- T
false.seq <- c()
# Loop through times
for (i in 1:length(times)){
# If not a spike, add index to false.sequence
if (!spikes$events[i]){
false.seq <- c(false.seq, i)
# Otherwise, check length of false sequence, if greater than gap time,
# save those indices to replace later
} else if (spikes$events[i]){
if (length(false.seq) <= gap.time & !first.gap){
to.replace <- c(to.replace, false.seq)
}
first.gap <- F
false.seq <- c()
}
}
# Replace gaps shorter than gap.time with T (meaning they are in an event)
spikes$events[to.replace] <- T
# Now we replace the T/F with an integer to distinguish between events
# Start by replacing F with NA and T with zero
spikes$events[!spikes$events] <- NA
spikes$events[spikes$events] <- 0
# Get indices of spikes
spike.points <- which(!is.na(spikes$events))
count <- 0
# Loop through spike points, if last point was not a spike, increase counter
for (i in spike.points){
if (is.na(spikes$events[i-1])){
count <- count + 1
spikes$events[i] <- count
} else {
spikes$events[i] <- count
}
}
# Get integers that uniquely define the different events
event.nums <- na.omit(unique(spikes$events))
# Filter events by the length threshold
for (i in 1:length(event.nums)){
this.spike <- which(spikes$events == event.nums[i])
if (length(this.spike) < length.threshold){
spikes$events[this.spike] <- NA
}
}
# Grab event number again after filtering by length
event.nums <- na.omit(unique(spikes$events))
# Number of events that we will perform localization / quantification on
n.ints <- length(event.nums)
# Perform localization and quantification on non-overlapping 30-minute intervals
} else {
# Get range of times, rounded to 30-minute intervals
date.range <- range(data$times)
date.range[1] <- ceiling_date(date.range[1], unit = "30 minutes")
date.range[2] <- floor_date(date.range[2], unit = "30 minutes")
# Times separating the 30-minute intervals
int.breaks <- seq(date.range[1], date.range[2], by = "30 min")
# Number of intervals
n.ints <- length(int.breaks) - 1
}
date.range
list.files <- "/simulation_files"
setwd("~/Documents/code/DLQ/demo")
sim.files <_ list.files("/simulation_files")
# Description:
# Performs emission event detection, localization, and quantification
# using output from the Gaussian puff dispersion model and CMS concentration
# observations.
# Author: William Daniels (wdaniels@mines.edu)
# Last Updated: December 2023
# Clear environment
if(!is.null(dev.list())){dev.off()}
rm(list = ls())
# Import necessary libraries
library(lubridate)
library(zoo)
library(rstudioapi)
if (commandArgs()[1] == "RStudio"){
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
}
# START USER INPUT
#---------------------------------------------------------------------------
# Set parameter values
gap.time           <- 30
length.threshold   <- 15
do.event.detection <- F
# Get directories
simulation.data.path <- "simulation_output.RData"
output.file.path <- "DLQ_output"
# Source helper files which contain helper functions
source('https://raw.github.com/wsdaniels/DLQ/master/code/HELPER_spike_detection_algorithm.R')
# END OF USER INPUT - NO MODIFICATION NECESSARY BELOW THIS POINT
#---------------------------------------------------------------------------
sim.files <- list.files("/simulation_files")
# Description:
# Performs emission event detection, localization, and quantification
# using output from the Gaussian puff dispersion model and CMS concentration
# observations.
# Author: William Daniels (wdaniels@mines.edu)
# Last Updated: December 2023
# Clear environment
if(!is.null(dev.list())){dev.off()}
rm(list = ls())
# Import necessary libraries
library(lubridate)
library(zoo)
library(rstudioapi)
if (commandArgs()[1] == "RStudio"){
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
}
# START USER INPUT
#---------------------------------------------------------------------------
# Set parameter values
gap.time           <- 30
length.threshold   <- 15
do.event.detection <- F
# Get directories
simulation.data.path <- "simulation_output.RData"
output.file.path <- "DLQ_output"
# Source helper files which contain helper functions
source('https://raw.github.com/wsdaniels/DLQ/master/code/HELPER_spike_detection_algorithm.R')
# END OF USER INPUT - NO MODIFICATION NECESSARY BELOW THIS POINT
#---------------------------------------------------------------------------
sim.files <- list.files("/simulation_files/")
sim.files <- list.files("./simulation_files/")
sim.files <- list.files("./simulation_files/")
sims <- vector(mode = "list", length = length(sim.files))
# Get directories
simulation.directory <- "./simulation_files"
sim.files <- list.files(simulation.directory)
i = 1
sim.files <- list.files(simulation.directory)
sims <- vector(mode = "list", length = length(sim.files))
this.sim <- read.csv(paste0(simulation.directory), "/", sim.files[i])
this.sim <- read.csv(paste0(simulation.directory, "/", sim.files[i]))
View(this.sim)
times <- this.sim$TimeStamp
sims[[i]] <- this.sim[,-1]
View(sims)
sim.files <- list.files(simulation.directory)
sims <- vector(mode = "list", length = length(sim.files))
for (i in 1:length(sim.files)){
this.sim <- read.csv(paste0(simulation.directory, "/", sim.files[i]))
times <- this.sim$TimeStamp
sims[[i]] <- this.sim[,-1]
}
View(sims)
names(sims) <- sim.files
View(sims)
strsplit(sim.files, ".")
sim.files
strsplit(sim.files, "\.")
strsplit(sim.files, "\\.")
apply(strsplit(sim.files, "\\."), function(X) X[[1]])
?apply
sapply(strsplit(sim.files, "\\."), function(X) X[[1]])
sim.files <- list.files(simulation.directory)
sims <- vector(mode = "list", length = length(sim.files))
names(sims) <- sapply(strsplit(sim.files, "\\."), function(X) X[[1]])
for (i in 1:length(sim.files)){
this.sim <- read.csv(paste0(simulation.directory, "/", sim.files[i]))
times <- this.sim$TimeStamp
sims[[i]] <- this.sim[,-1]
}
View(sims)
# Get directories
simulation.directory <- "./simulation_files/"
output.file.path <- "./"
# Source helper files which contain helper functions
source('https://raw.github.com/wsdaniels/DLQ/master/code/HELPER_spike_detection_algorithm.R')
sim.files <- list.files(simulation.directory)
sim.files
sims <- vector(mode = "list", length = length(sim.files))
names(sims) <- sapply(strsplit(sim.files, "\\."), function(X) X[[1]])
View(sims)
